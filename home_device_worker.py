import os
import time
import json
import logging
from datetime import datetime
from typing import Optional
from string import printable
from functools import wraps

from groq import Groq
from youtube_transcript_api import YouTubeTranscriptApi

from redis_wrapper import value_cache, QUEUE_NAME, WORKER_HEARTBEAT
from helpers import to_audio_location
from video_processing import download_video_mp3

logging.basicConfig(level=logging.INFO)

GROQ_API_KEY = os.environ.get("GROQ_API_KEY")
assert GROQ_API_KEY is not None, "GROQ_API_KEY environment variable is not set."
groq_client = Groq(api_key=GROQ_API_KEY)

def get_youtube_str_transcript(video_id: str) -> Optional[str]:
    """
    Get the transcript of a video from the YouTube Transcript API if manually generated English 
    subtitles exist. Strips out newline characters.
    
    :param video_id: The YouTube video ID.
    :return: The transcript string if found, otherwise None.
    """
    try:
        transcript_obj = YouTubeTranscriptApi.list_transcripts(video_id).find_manually_created_transcript(["en", "en-US"])
        transcript_list = transcript_obj.fetch()
        transcript_text = " ".join([item["text"] for item in transcript_list])
        transcript_text = transcript_text.replace("\n", " ")
        # Filter out non-printable characters
        transcript_text = "".join(char for char in transcript_text if char in printable)
        return transcript_text
    except Exception:
        logging.warning(f"YouTube Transcript API failed to find a manual transcript for video id: {video_id}.")
        return None

def create_whisper_transcript(video_id: str, model: str = "whisper-large-v3") -> str:
    """
    Generate a transcript using Groq's Whisper v3 API.
    
    :param video_id: The video ID of the YouTube video we want to create a transcript for.
    :param model: The model to use. Default is 'whisper-large-v3'.
    :return: The transcript text generated by Whisper.
    :raises Exception: If the file isn't found or any unexpected error occurs.
    """
    download_video_mp3(video_id)
    file_path = to_audio_location(video_id)
    try:
        file_size = os.path.getsize(file_path)
        file_size_mb = file_size / (1024 * 1024)  # Convert to MB
        logging.info(f"File size for {file_path}: {file_size_mb:.2f} MB")

        with open(file_path, "rb") as audio_file:
            logging.info(f"Starting transcription for: {file_path}")
            start_time = time.time()

            # Make the API call
            transcript = groq_client.audio.transcriptions.create(
                model=model,
                file=audio_file
            )
            
            end_time = time.time()
            logging.info(f"Transcription completed in {end_time - start_time:.2f} seconds for {file_path}")

            return transcript.text

    except FileNotFoundError as e:
        logging.error(f"File not found: {file_path}")
        raise Exception(f"File not found: {file_path}") from e

    except Exception as e:
        logging.error(f"An unexpected error occurred: {str(e)}")
        raise Exception(f"An unexpected error occurred: {str(e)}") from e
    finally:
        # Clean up the audio file
        if os.path.exists(file_path):
            os.remove(file_path)

def cleanup_transcript_status(func):
    @wraps(func)
    def wrapper(video_id: str, task_type: str, *args, **kwargs):
        status_key = f"transcript_status:{task_type}:{video_id}"
        try:
            return func(video_id, task_type, *args, **kwargs)
        finally:
            value_cache.delete(status_key)
    return wrapper

@cleanup_transcript_status
def process_job(video_id: str, task_type: str):
    """
    Executes the correct transcription method based on task_type.
    If the first attempt fails or returns None, automatically
    fall back to the other method.
    Saves the final transcript to Redis or marks failed on error.
    """

    # We'll keep the status key as-is for the original request:
    status_key_original = f"transcript_status:{task_type}:{video_id}"
    value_cache.set(status_key_original, "in_progress")

    # We may need to store the transcript in the relevant method's key
    # so the user can find it in their poll. The fallback order is:
    #   [task_type, the_other_method]
    fallback_order = []
    if task_type == "audio":
        fallback_order = ["audio", "youtube"]
    else:
        fallback_order = ["youtube", "audio"]

    transcript = None
    final_method_used = None

    # Try each method in fallback_order until we succeed
    for method in fallback_order:
        logging.info(f"[Worker] Attempting transcription with method '{method}' for video ID: {video_id}")
        try:
            if method == "audio":
                transcript = create_whisper_transcript(video_id)
            else:  # method == "youtube"
                transcript = get_youtube_str_transcript(video_id)

            if transcript:
                final_method_used = method
                break
            else:
                logging.warning(f"[Worker] Method '{method}' failed or returned no transcript for video_id={video_id}")

        except Exception as e:
            logging.exception(f"[Worker] Error using method '{method}' for video_id={video_id}: {e}")

    if transcript and final_method_used:
        # Store in Redis under transcript:<final_method_used>:<video_id>
        transcript_key = f"transcript:{final_method_used}:{video_id}"
        value_cache.set(transcript_key, transcript, ex=60 * 60 * 24)  # e.g. 24-hour expiration
        logging.info(f"[Worker] Successfully stored {final_method_used} transcript for video_id={video_id}")
    else:
        # Could be an error or no subtitles in both fallback attempts
        logging.warning(f"[Worker] Both fallback methods failed for video_id={video_id}")

def main_loop():
    logging.info("Worker started. Listening for tasks...")
    SLEEP_TIME = 5 * 60  # 10 minutes
    while True:
        value_cache.setex(WORKER_HEARTBEAT, SLEEP_TIME, "alive")

        # BLPOP blocks until there's a job
        logging.info(f"Reconnecting to queue at {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        result = value_cache.blpop([QUEUE_NAME], timeout=SLEEP_TIME)
        if not result:
            continue

        queue_name, raw_data = result
        try:
            job_data = json.loads(raw_data)
            video_id = job_data["video_id"]
            task_type = job_data["task_type"]
            logging.info(f"Picked up job: {video_id}, task_type={task_type}")
            start_time = time.time()
            process_job(video_id, task_type)
            logging.info(f"Job completed in {time.time() - start_time:.2f} seconds.")
        except Exception as e:
            logging.exception(f"Error decoding job data: {raw_data}, {e}")

def run_worker():
    while True:
        try:
            main_loop()
        except Exception as e:
            logging.exception(f"Worker loop crashed. Restarting in 1sec... {e}")
            time.sleep(1)

if __name__ == "__main__":
    run_worker()
